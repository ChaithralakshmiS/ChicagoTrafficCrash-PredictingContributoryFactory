{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: MacOSX\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "#sklearn\n",
    "from sklearn import datasets, svm, metrics,tree\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "#preprocessing\n",
    "from sklearn.preprocessing import StandardScaler,normalize\n",
    "# Dimenionality Reduction\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn import random_projection\n",
    "#Feature selection\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "#Under sampling\n",
    "#from imblearn.under_sampling import RandomUnderSampler\n",
    "#Over sampling\n",
    "#from imblearn.over_sampling import SMOTE, BorderlineSMOTE, SVMSMOTE, SMOTENC,RandomOverSampler\n",
    "#Combined sampling\n",
    "#from imblearn.combine import SMOTETomek\n",
    "#Algorithms\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import VotingClassifier,AdaBoostClassifier,RandomForestClassifier,ExtraTreesClassifier,GradientBoostingClassifier,GradientBoostingRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB,GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression,RidgeClassifier,Perceptron,PassiveAggressiveClassifier,RidgeClassifierCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.utils import resample\n",
    "from sklearn.pipeline import *\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import f1_score,confusion_matrix,classification_report,make_scorer,average_precision_score,precision_recall_curve\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "#import pandas_ml as pdml\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from scipy.stats import itemfreq\n",
    "import importlib\n",
    "from importlib import reload  \n",
    "from collections import defaultdict,Counter\n",
    "\n",
    "from sklearn import preprocessing\n",
    "%matplotlib inline \n",
    "pd.options.display.max_columns=200\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score,f1_score\n",
    "\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "#Graphs\n",
    "%matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "#import seaborn as sns;\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Importing preprocessing file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CRASH :  (234866, 23)\n",
      "VEHICLE :  (474634, 17)\n",
      "PEOPLE :  (413775, 16)\n",
      "['LANE_CNT', 'INTERSECTION_RELATED_I', 'NOT_RIGHT_OF_WAY_I', 'DOORING_I', 'WORK_ZONE_I', 'NUM_UNITS']\n",
      "['UNIT_TYPE', 'VEHICLE_ID', 'CMRC_VEH_I', 'VEHICLE_YEAR', 'VEHICLE_DEFECT', 'VEHICLE_TYPE', 'VEHICLE_USE', 'MANEUVER', 'EXCEED_SPEED_LIMIT_I', 'CMV_ID', 'GVWR', 'TOTAL_VEHICLE_LENGTH', 'AXLE_CNT', 'VEHICLE_CONFIG']\n",
      "['VEHICLE_ID', 'SEX', 'AGE', 'DRIVERS_LICENSE_CLASS', 'SAFETY_EQUIPMENT', 'DRIVER_ACTION', 'DRIVER_VISION', 'PHYSICAL_CONDITION', 'PEDPEDAL_ACTION', 'PEDPEDAL_VISIBILITY', 'PEDPEDAL_LOCATION', 'BAC_RESULT VALUE', 'CELL_PHONE_USE']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "Vpa rd_no :  (234682, 1)\n",
      "Vpa unit 1 :  (234732, 31)\n",
      "Vpa unit 2 :  (234762, 61)\n",
      "Vpa unit 3 :  (234762, 91)\n",
      "Vpa unit 4 :  (234762, 121)\n",
      "Vpa unit 5 :  (234762, 151)\n",
      "Vpa unit 6 :  (234762, 181)\n",
      "cvp with duplicates: (234641, 203)\n",
      "cvp without duplicates: (234584, 203)\n",
      "Dataframe size after adding dummies to crashes columns:  (234584, 287)\n",
      "Dataframe size after adding dummies to vehicles columns:  (234584, 694)\n",
      "Dataframe size after adding dummies to peoples columns:  (234584, 929)\n"
     ]
    }
   ],
   "source": [
    "import Preprocessing as pp\n",
    "\n",
    "#reload(pp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Splitting target variable from other variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pp.cvp_ohe\n",
    "train_data=df.copy(deep=True)\n",
    "train_data=train_data.drop(['PRIM_CONTRIBUTORY_CAUSE', 'SEC_CONTRIBUTORY_CAUSE'], axis=1)\n",
    "train_labels=df[['PRIM_CONTRIBUTORY_CAUSE']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ax = sns.heatmap(train_labels, vmin=0, vmax=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Splitting to train and test \n",
    "###### Scaling of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train_data, train_labels,test_size=0.20,stratify=train_labels,random_state=42)\n",
    "scaler=StandardScaler()\n",
    "X_train_scaled=scaler.fit_transform(X_train)\n",
    "X_test_scaled=scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithms Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian Naive Bayes - Approach 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_selection=PCA(n_components=500)\n",
    "clf=GaussianNB()\n",
    "\n",
    "pipe_clf = make_pipeline(feature_selection,clf)\n",
    "pipe_clf.fit(X_train_scaled, y_train)\n",
    "y_pred_GNB1 = pipe_clf.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Performance Evaluation for Gaussian Naive Bayes - Approach 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********Gaussian Naive Bayes, Standard Scaled, PCA=500 ********\n",
      "F1-score_micro =  0.07123217597033059\n",
      "F1-score =  0.10507073574861406\n",
      "Precision =  0.3217250962687425\n",
      "Recall Score =  0.07123217597033059\n",
      "Stored 'f1_score_micro_1_GNB1' (float64)\n",
      "Stored 'f1_score_wt_1_GNB1' (float64)\n",
      "Stored 'precision_score_wt_1_GNB1' (float64)\n",
      "Stored 'recall_score_wt_1_GNB1' (float64)\n"
     ]
    }
   ],
   "source": [
    "print('********Gaussian Naive Bayes, Standard Scaled, PCA=500','********')\n",
    "f1_score_micro_1_GNB1 = metrics.f1_score(y_test, y_pred_GNB1, average='micro')\n",
    "f1_score_wt_1_GNB1 = metrics.f1_score(y_test,y_pred_GNB1,average='weighted')\n",
    "precision_score_wt_1_GNB1 =metrics.precision_score(y_test, y_pred_GNB1, average='weighted')\n",
    "recall_score_wt_1_GNB1 =metrics.recall_score(y_test, y_pred_GNB1, average='weighted')\n",
    "\n",
    "print('F1-score_micro = ',f1_score_micro_1_GNB1)\n",
    "print('F1-score = ',f1_score_wt_1_GNB1)\n",
    "print('Precision = ',precision_score_wt_1_GNB1)\n",
    "print('Recall Score = ',recall_score_wt_1_GNB1)\n",
    "\n",
    "%store f1_score_micro_1_GNB1\n",
    "%store f1_score_wt_1_GNB1\n",
    "%store precision_score_wt_1_GNB1\n",
    "%store recall_score_wt_1_GNB1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian Naive Bayes - Approach 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_selection=VarianceThreshold()\n",
    "clf=GaussianNB()\n",
    "\n",
    "pipe_clf = make_pipeline(feature_selection,clf)\n",
    "pipe_clf.fit(X_train_scaled, y_train)\n",
    "y_pred_GNB2 = pipe_clf.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Performance Evaluation for Gaussian Naive Bayes - Approach 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********Gaussian Naive Bayes, Standard Scaled, Variance threshold ********\n",
      "F1-score_micro =  0.005456444359187501\n",
      "F1-score =  0.0038950982391299923\n",
      "Precision =  0.2084925981060008\n",
      "Recall Score =  0.005456444359187501\n",
      "Stored 'f1_score_micro_2_GNB2' (float64)\n",
      "Stored 'f1_score_wt_2_GNB2' (float64)\n",
      "Stored 'precision_score_wt_2_GNB2' (float64)\n",
      "Stored 'recall_score_wt_2_GNB2' (float64)\n"
     ]
    }
   ],
   "source": [
    "print('********Gaussian Naive Bayes, Standard Scaled, Variance threshold','********')\n",
    "\n",
    "f1_score_micro_2_GNB2 = metrics.f1_score(y_test, y_pred_GNB2, average='micro')\n",
    "f1_score_wt_2_GNB2 = metrics.f1_score(y_test,y_pred_GNB2,average='weighted')\n",
    "precision_score_wt_2_GNB2 = metrics.precision_score(y_test, y_pred_GNB2, average='weighted')\n",
    "recall_score_wt_2_GNB2 =metrics.recall_score(y_test, y_pred_GNB2, average='weighted')\n",
    "\n",
    "print('F1-score_micro = ',f1_score_micro_2_GNB2)\n",
    "print('F1-score = ',f1_score_wt_2_GNB2)\n",
    "print('Precision = ',precision_score_wt_2_GNB2)\n",
    "print('Recall Score = ',recall_score_wt_2_GNB2)\n",
    "\n",
    "%store f1_score_micro_2_GNB2\n",
    "%store f1_score_wt_2_GNB2\n",
    "%store precision_score_wt_2_GNB2\n",
    "%store recall_score_wt_2_GNB2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian Naive Bayes - Approach 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_selection=TruncatedSVD(n_components=500)\n",
    "clf=GaussianNB()\n",
    "\n",
    "pipe_clf = make_pipeline(feature_selection,clf)\n",
    "pipe_clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred_GNB3 = pipe_clf.predict(X_test_scaled)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performance Evaluation for Gaussian Naive Bayes - Approach 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********Gaussian Naive Bayes, Standard Scaled, Truncated SVD ********\n",
      "F1-score_micro =  0.06944178016497218\n",
      "F1-score =  0.10224143429953816\n",
      "Precision =  0.3192906519134552\n",
      "Recall Score =  0.06944178016497218\n",
      "Stored 'f1_score_micro_2_GNB3' (float64)\n",
      "Stored 'f1_score_wt_2_GNB3' (float64)\n",
      "Stored 'precision_score_wt_2_GNB3' (float64)\n",
      "Stored 'recall_score_wt_2_GNB3' (float64)\n"
     ]
    }
   ],
   "source": [
    "print('********Gaussian Naive Bayes, Standard Scaled, Truncated SVD','********')\n",
    "\n",
    "f1_score_micro_2_GNB3 = metrics.f1_score(y_test, y_pred_GNB3, average='micro')\n",
    "f1_score_wt_2_GNB3 = metrics.f1_score(y_test,y_pred_GNB3,average='weighted')\n",
    "precision_score_wt_2_GNB3 = metrics.precision_score(y_test, y_pred_GNB3, average='weighted')\n",
    "recall_score_wt_2_GNB3 = metrics.recall_score(y_test, y_pred_GNB3, average='weighted')\n",
    "\n",
    "print('F1-score_micro = ',f1_score_micro_2_GNB3)\n",
    "print('F1-score = ',f1_score_wt_2_GNB3)\n",
    "print('Precision = ',precision_score_wt_2_GNB3)\n",
    "print('Recall Score = ',recall_score_wt_2_GNB3)\n",
    "\n",
    "%store f1_score_micro_2_GNB3\n",
    "%store f1_score_wt_2_GNB3\n",
    "%store precision_score_wt_2_GNB3\n",
    "%store recall_score_wt_2_GNB3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithm - II "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression - Approach 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_selection=PCA(n_components=500)\n",
    "clf=LogisticRegression(random_state=0, solver='lbfgs', multi_class='multinomial')\n",
    "\n",
    "pipe_clf = make_pipeline(feature_selection,clf)\n",
    "pipe_clf.fit(X_train_scaled, y_train)\n",
    "y_pred_LR1 = pipe_clf.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performance Evaluation for Logistic Regression - Approach 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********Logistic Regression, Standard Scaled, PCA=500 ********\n",
      "F1-score_micro =  0.6232495683867255\n",
      "F1-score =  0.580873794994892\n",
      "Precision =  0.5805246278101315\n",
      "Recall Score =  0.6232495683867255\n",
      "Stored 'f1_score_micro_1_LR1' (float64)\n",
      "Stored 'f1_score_wt_1_LR1' (float64)\n",
      "Stored 'precision_score_wt_1_LR1' (float64)\n",
      "Stored 'recall_score_wt_1_LR1' (float64)\n"
     ]
    }
   ],
   "source": [
    "print('********Logistic Regression, Standard Scaled, PCA=500','********')\n",
    "f1_score_micro_1_LR1 = metrics.f1_score(y_test, y_pred_LR1, average='micro')\n",
    "f1_score_wt_1_LR1 = metrics.f1_score(y_test,y_pred_LR1,average='weighted')\n",
    "precision_score_wt_1_LR1 = metrics.precision_score(y_test, y_pred_LR1, average='weighted')\n",
    "recall_score_wt_1_LR1 = metrics.recall_score(y_test, y_pred_LR1, average='weighted')\n",
    "\n",
    "print('F1-score_micro = ',f1_score_micro_1_LR1)\n",
    "print('F1-score = ',f1_score_wt_1_LR1)\n",
    "print('Precision = ',precision_score_wt_1_LR1)\n",
    "print('Recall Score = ',recall_score_wt_1_LR1)\n",
    "\n",
    "%store f1_score_micro_1_LR1\n",
    "%store f1_score_wt_1_LR1\n",
    "%store precision_score_wt_1_LR1\n",
    "%store recall_score_wt_1_LR1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression - Approach 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_selection=VarianceThreshold()\n",
    "clf=LogisticRegression(random_state=0, solver='lbfgs', multi_class='multinomial')\n",
    "\n",
    "pipe_clf = make_pipeline(feature_selection,clf)\n",
    "pipe_clf.fit(X_train_scaled, y_train)\n",
    "y_pred_LR2 = pipe_clf.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performance Evaluation for Logistic Regression - Approach 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********Logistic Regression, Standard Scaled, Variance threshold ********\n",
      "F1-score_micro =  0.6293454398192553\n",
      "F1-score =  0.5898537709788344\n",
      "Precision =  0.5899418346929847\n",
      "Recall Score =  0.6293454398192553\n",
      "Stored 'f1_score_micro_2_LR2' (float64)\n",
      "Stored 'f1_score_wt_2_LR2' (float64)\n",
      "Stored 'precision_score_wt_2_LR2' (float64)\n",
      "Stored 'recall_score_wt_2_LR2' (float64)\n"
     ]
    }
   ],
   "source": [
    "print('********Logistic Regression, Standard Scaled, Variance threshold','********')\n",
    "\n",
    "f1_score_micro_2_LR2 = metrics.f1_score(y_test, y_pred_LR2, average='micro')\n",
    "f1_score_wt_2_LR2 = metrics.f1_score(y_test,y_pred_LR2,average='weighted')\n",
    "precision_score_wt_2_LR2 = metrics.precision_score(y_test, y_pred_LR2, average='weighted')\n",
    "recall_score_wt_2_LR2 = metrics.recall_score(y_test, y_pred_LR2, average='weighted')\n",
    "\n",
    "print('F1-score_micro = ',f1_score_micro_2_LR2)\n",
    "print('F1-score = ',f1_score_wt_2_LR2)\n",
    "print('Precision = ',precision_score_wt_2_LR2)\n",
    "print('Recall Score = ',recall_score_wt_2_LR2)\n",
    "\n",
    "%store f1_score_micro_2_LR2\n",
    "%store f1_score_wt_2_LR2\n",
    "%store precision_score_wt_2_LR2\n",
    "%store recall_score_wt_2_LR2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression - Approach 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_selection=TruncatedSVD(n_components=500)\n",
    "clf=LogisticRegression(random_state=0, solver='lbfgs', multi_class='multinomial')\n",
    "\n",
    "pipe_clf = make_pipeline(feature_selection,clf)\n",
    "pipe_clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred_LR3 = pipe_clf.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performance Evaluation for Logistic Regression - Approach 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********Logistic Regression, Standard Scaled, Truncated SVD ********\n",
      "F1-score_micro =  0.6235905961591747\n",
      "F1-score =  0.5817147236555426\n",
      "Precision =  0.5815207708644762\n",
      "Recall Score =  0.6235905961591747\n",
      "Stored 'f1_score_tsvd_micro_LR3' (float64)\n",
      "Stored 'f1_score_tsvd_wt_LR3' (float64)\n",
      "Stored 'precision_score_tsvd_wt_LR3' (float64)\n",
      "Stored 'recall_score_tsvd_wt_LR3' (float64)\n"
     ]
    }
   ],
   "source": [
    "print('********Logistic Regression, Standard Scaled, Truncated SVD','********')\n",
    "\n",
    "f1_score_tsvd_micro_LR3 = metrics.f1_score(y_test, y_pred_LR3, average='micro')\n",
    "f1_score_tsvd_wt_LR3 = metrics.f1_score(y_test,y_pred_LR3,average='weighted')\n",
    "precision_score_tsvd_wt_LR3 = metrics.precision_score(y_test, y_pred_LR3, average='weighted')\n",
    "recall_score_tsvd_wt_LR3 = metrics.recall_score(y_test, y_pred_LR3, average='weighted')\n",
    "\n",
    "print('F1-score_micro = ',f1_score_tsvd_micro_LR3)\n",
    "print('F1-score = ',f1_score_tsvd_wt_LR3)\n",
    "print('Precision = ',precision_score_tsvd_wt_LR3)\n",
    "print('Recall Score = ',recall_score_tsvd_wt_LR3)\n",
    "\n",
    "%store f1_score_tsvd_micro_LR3\n",
    "%store f1_score_tsvd_wt_LR3\n",
    "%store precision_score_tsvd_wt_LR3\n",
    "%store recall_score_tsvd_wt_LR3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithm III"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest - Approach 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_selection=PCA(n_components=500)\n",
    "clf=RandomForestClassifier(n_estimators=100, random_state=100)\n",
    "\n",
    "pipe_clf = make_pipeline(feature_selection,clf)\n",
    "pipe_clf.fit(X_train_scaled, y_train)\n",
    "y_pred_RF1 = pipe_clf.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performance Evaluation for Random Forest - Approach 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********Random Forest, Standard Scaled, PCA=500 ********\n",
      "F1-score_micro =  0.5659569026152568\n",
      "F1-score =  0.5084327706642776\n",
      "Precision =  0.5500017743952035\n",
      "Recall Score =  0.5659569026152568\n",
      "Stored 'f1_score_micro_1_RF1' (float64)\n",
      "Stored 'f1_score_wt_1_RF1' (float64)\n",
      "Stored 'precision_score_wt_1_RF1' (float64)\n",
      "Stored 'recall_score_wt_1_RF1' (float64)\n"
     ]
    }
   ],
   "source": [
    "print('********Random Forest, Standard Scaled, PCA=500','********')\n",
    "f1_score_micro_1_RF1 = metrics.f1_score(y_test, y_pred_RF1, average='micro')\n",
    "f1_score_wt_1_RF1 = metrics.f1_score(y_test,y_pred_RF1,average='weighted')\n",
    "precision_score_wt_1_RF1 = metrics.precision_score(y_test, y_pred_RF1, average='weighted')\n",
    "recall_score_wt_1_RF1 = metrics.recall_score(y_test, y_pred_RF1, average='weighted')\n",
    "\n",
    "print('F1-score_micro = ',f1_score_micro_1_RF1)\n",
    "print('F1-score = ',f1_score_wt_1_RF1)\n",
    "print('Precision = ',precision_score_wt_1_RF1)\n",
    "print('Recall Score = ',recall_score_wt_1_RF1)\n",
    "\n",
    "%store f1_score_micro_1_RF1\n",
    "%store f1_score_wt_1_RF1\n",
    "%store precision_score_wt_1_RF1\n",
    "%store recall_score_wt_1_RF1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest - Approach 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_selection=VarianceThreshold()\n",
    "clf=RandomForestClassifier(n_estimators=100, random_state=100)\n",
    "\n",
    "pipe_clf = make_pipeline(feature_selection,clf)\n",
    "pipe_clf.fit(X_train_scaled, y_train)\n",
    "y_pred_RF2 = pipe_clf.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performance Evaluation for Random Forest - Approach 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********Random Forest, Standard Scaled, Variance threshold ********\n",
      "F1-score_micro =  0.6396828441716222\n",
      "F1-score =  0.591356582090985\n",
      "Precision =  0.6195473528899941\n",
      "Recall Score =  0.6396828441716222\n",
      "Stored 'f1_score_micro_2_RF2' (float64)\n",
      "Stored 'f1_score_wt_2_RF2' (float64)\n",
      "Stored 'precision_score_wt_2_RF2' (float64)\n",
      "Stored 'recall_score_wt_2_RF2' (float64)\n"
     ]
    }
   ],
   "source": [
    "print('********Random Forest, Standard Scaled, Variance threshold','********')\n",
    "\n",
    "f1_score_micro_2_RF2 = metrics.f1_score(y_test, y_pred_RF2, average='micro')\n",
    "f1_score_wt_2_RF2 = metrics.f1_score(y_test,y_pred_RF2,average='weighted')\n",
    "precision_score_wt_2_RF2 = metrics.precision_score(y_test, y_pred_RF2, average='weighted')\n",
    "recall_score_wt_2_RF2 = metrics.recall_score(y_test, y_pred_RF2, average='weighted')\n",
    "\n",
    "print('F1-score_micro = ',f1_score_micro_2_RF2)\n",
    "print('F1-score = ',f1_score_wt_2_RF2)\n",
    "print('Precision = ',precision_score_wt_2_RF2)\n",
    "print('Recall Score = ',recall_score_wt_2_RF2)\n",
    "\n",
    "%store f1_score_micro_2_RF2\n",
    "%store f1_score_wt_2_RF2\n",
    "%store precision_score_wt_2_RF2\n",
    "%store recall_score_wt_2_RF2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest - Approach 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_selection=TruncatedSVD(n_components=500)\n",
    "clf=RandomForestClassifier(n_estimators=100, random_state=100)\n",
    "\n",
    "pipe_clf = make_pipeline(feature_selection,clf)\n",
    "pipe_clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred_RF3 = pipe_clf.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performance Evaluation for Random Forest - Approach 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********Random Forest, Standard Scaled, Variance threshold ********\n",
      "F1-score_micro =  0.5655945606070294\n",
      "F1-score =  0.5073501551584017\n",
      "Precision =  0.5453460888515417\n",
      "Recall Score =  0.5655945606070294\n",
      "Stored 'f1_score_micro_2_RF3' (float64)\n",
      "Stored 'f1_score_wt_2_RF3' (float64)\n",
      "Stored 'precision_score_wt_2_RF3' (float64)\n",
      "Stored 'recall_score_wt_2_RF3' (float64)\n"
     ]
    }
   ],
   "source": [
    "print('********Random Forest, Standard Scaled, Variance threshold','********')\n",
    "\n",
    "f1_score_micro_2_RF3 = metrics.f1_score(y_test, y_pred_RF3, average='micro')\n",
    "f1_score_wt_2_RF3 = metrics.f1_score(y_test,y_pred_RF3,average='weighted')\n",
    "precision_score_wt_2_RF3 = metrics.precision_score(y_test, y_pred_RF3, average='weighted')\n",
    "recall_score_wt_2_RF3 = metrics.recall_score(y_test, y_pred_RF3, average='weighted')\n",
    "\n",
    "print('F1-score_micro = ',f1_score_micro_2_RF3)\n",
    "print('F1-score = ',f1_score_wt_2_RF3)\n",
    "print('Precision = ',precision_score_wt_2_RF3)\n",
    "print('Recall Score = ',recall_score_wt_2_RF3)\n",
    "\n",
    "%store f1_score_micro_2_RF3\n",
    "%store f1_score_wt_2_RF3\n",
    "%store precision_score_wt_2_RF3\n",
    "%store recall_score_wt_2_RF3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest - Approach 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_selection=PCA(n_components=500)\n",
    "clf=RandomForestClassifier(n_estimators=1000, max_depth=5, random_state=100, max_features=10)\n",
    "\n",
    "pipe_clf = make_pipeline(feature_selection,clf)\n",
    "pipe_clf.fit(X_train_scaled, y_train)\n",
    "y_pred_RF4 = pipe_clf.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performance Evaluation for Random Forest - Approach 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********Random Forest, Standard Scaled, PCA=500 ********\n",
      "F1-score_micro =  0.38727966408764414\n",
      "F1-score =  0.23958618920659525\n",
      "Precision =  0.3419131999482666\n",
      "Recall Score =  0.38727966408764414\n",
      "Stored 'f1_score_micro_2_RF4' (float64)\n",
      "Stored 'f1_score_wt_2_RF4' (float64)\n",
      "Stored 'precision_score_wt_2_RF4' (float64)\n",
      "Stored 'recall_score_wt_2_RF4' (float64)\n"
     ]
    }
   ],
   "source": [
    "print('********Random Forest, Standard Scaled, PCA=500','********')\n",
    "\n",
    "f1_score_micro_2_RF4 = metrics.f1_score(y_test, y_pred_RF4, average='micro')\n",
    "f1_score_wt_2_RF4 = metrics.f1_score(y_test,y_pred_RF4,average='weighted')\n",
    "precision_score_wt_2_RF4 = metrics.precision_score(y_test, y_pred_RF4, average='weighted')\n",
    "recall_score_wt_2_RF4 = metrics.recall_score(y_test, y_pred_RF4, average='weighted')\n",
    "\n",
    "print('F1-score_micro = ',f1_score_micro_2_RF4)\n",
    "print('F1-score = ',f1_score_wt_2_RF4)\n",
    "print('Precision = ',precision_score_wt_2_RF4)\n",
    "print('Recall Score = ',recall_score_wt_2_RF4)\n",
    "\n",
    "%store f1_score_micro_2_RF4\n",
    "%store f1_score_wt_2_RF4\n",
    "%store precision_score_wt_2_RF4\n",
    "%store recall_score_wt_2_RF4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "algorithm_1 = {'f1_score_micro_1_GNB1':f1_score_micro_1_GNB1,\n",
    "'f1_score_wt_1_GNB1': f1_score_wt_1_GNB1,\n",
    "'precision_score_wt_1_GNB1': precision_score_wt_1_GNB1,\n",
    "'recall_score_wt_1_GNB1':recall_score_wt_1_GNB1,\n",
    "'f1_score_micro_2_GNB2':f1_score_micro_2_GNB2,\n",
    "'f1_score_wt_2_GNB2':f1_score_wt_2_GNB2,\n",
    "'precision_score_wt_2_GNB2':precision_score_wt_2_GNB2,\n",
    "'recall_score_wt_2_GNB2':recall_score_wt_2_GNB2,\n",
    "'f1_score_micro_2_GNB3':f1_score_micro_2_GNB3,\n",
    "'f1_score_wt_2_GNB3':f1_score_wt_2_GNB3,\n",
    "'precision_score_wt_2_GNB3':precision_score_wt_2_GNB3,\n",
    "'recall_score_wt_2_GNB3':recall_score_wt_2_GNB3,\n",
    "'f1_score_micro_1_LR1':f1_score_micro_1_LR1,\n",
    "'f1_score_wt_1_LR1':f1_score_wt_1_LR1,\n",
    "'precision_score_wt_1_LR1':precision_score_wt_1_LR1,\n",
    "'recall_score_wt_1_LR1':recall_score_wt_1_LR1,\n",
    "'f1_score_micro_2_LR2':f1_score_micro_2_LR2,\n",
    "'f1_score_wt_2_LR2':f1_score_wt_2_LR2,\n",
    "'precision_score_wt_2_LR2':precision_score_wt_2_LR2,\n",
    "'recall_score_wt_2_LR2':recall_score_wt_2_LR2,\n",
    "'f1_score_tsvd_micro_LR3':f1_score_tsvd_micro_LR3,\n",
    "'f1_score_tsvd_wt_LR3':f1_score_tsvd_wt_LR3,\n",
    "'precision_score_tsvd_wt_LR3':precision_score_tsvd_wt_LR3,\n",
    "'recall_score_tsvd_wt_LR3':recall_score_tsvd_wt_LR3,\n",
    "'f1_score_micro_1_RF1':f1_score_micro_1_RF1,\n",
    "'f1_score_wt_1_RF1':f1_score_wt_1_RF1,\n",
    "'precision_score_wt_1_RF1':precision_score_wt_1_RF1,\n",
    "'recall_score_wt_1_RF1':recall_score_wt_1_RF1,\n",
    "'f1_score_micro_2_RF2':f1_score_micro_2_RF2,\n",
    "'f1_score_wt_2_RF2':f1_score_wt_2_RF2,\n",
    "'precision_score_wt_2_RF2':precision_score_wt_2_RF2,\n",
    "'recall_score_wt_2_RF2':recall_score_wt_2_RF2,\n",
    "'f1_score_micro_2_RF3':f1_score_micro_2_RF3,\n",
    "'f1_score_wt_2_RF3':f1_score_wt_2_RF3,\n",
    "'precision_score_wt_2_RF3':precision_score_wt_2_RF3,\n",
    "'recall_score_wt_2_RF3':recall_score_wt_2_RF3,\n",
    "'f1_score_micro_2_RF4':f1_score_micro_2_RF4,\n",
    "'f1_score_wt_2_RF4':f1_score_wt_2_RF4,\n",
    "'precision_score_wt_2_RF4':precision_score_wt_2_RF4,\n",
    "'recall_score_wt_2_RF4':recall_score_wt_2_RF4\n",
    "}\n",
    "\n",
    "pickle.dump(algorithm_1,open(\"algorithm_1.p\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
