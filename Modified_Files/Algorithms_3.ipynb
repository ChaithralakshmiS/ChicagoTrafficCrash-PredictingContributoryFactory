{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "#sklearn\n",
    "from sklearn import datasets, svm, metrics,tree\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "#preprocessing\n",
    "from sklearn.preprocessing import StandardScaler,normalize\n",
    "# Dimenionality Reduction\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn import random_projection\n",
    "#Feature selection\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "#Under sampling\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "#Over sampling\n",
    "from imblearn.over_sampling import SMOTE, BorderlineSMOTE, SVMSMOTE, SMOTENC,RandomOverSampler\n",
    "#Combined sampling\n",
    "from imblearn.combine import SMOTETomek\n",
    "#Algorithms\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import VotingClassifier,AdaBoostClassifier,RandomForestClassifier,ExtraTreesClassifier,GradientBoostingClassifier,GradientBoostingRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB,GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.linear_model import LogisticRegression,RidgeClassifier,Perceptron,PassiveAggressiveClassifier,RidgeClassifierCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.utils import resample\n",
    "from sklearn.pipeline import *\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import f1_score,confusion_matrix,classification_report,make_scorer,average_precision_score,precision_recall_curve\n",
    "\n",
    "#import pandas_ml as pdml\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from scipy.stats import itemfreq\n",
    "import importlib\n",
    "from importlib import reload  \n",
    "from collections import defaultdict,Counter\n",
    "\n",
    "from sklearn import preprocessing\n",
    "%matplotlib inline \n",
    "pd.options.display.max_columns=200\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score,f1_score\n",
    "\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Importing preprocessing file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CRASH :  (234866, 23)\n",
      "VEHICLE :  (474634, 17)\n",
      "PEOPLE :  (413775, 16)\n",
      "['LANE_CNT', 'INTERSECTION_RELATED_I', 'NOT_RIGHT_OF_WAY_I', 'DOORING_I', 'WORK_ZONE_I', 'NUM_UNITS']\n",
      "['UNIT_TYPE', 'VEHICLE_ID', 'CMRC_VEH_I', 'VEHICLE_YEAR', 'VEHICLE_DEFECT', 'VEHICLE_TYPE', 'VEHICLE_USE', 'MANEUVER', 'EXCEED_SPEED_LIMIT_I', 'CMV_ID', 'GVWR', 'TOTAL_VEHICLE_LENGTH', 'AXLE_CNT', 'VEHICLE_CONFIG']\n",
      "['VEHICLE_ID', 'SEX', 'AGE', 'DRIVERS_LICENSE_CLASS', 'SAFETY_EQUIPMENT', 'DRIVER_ACTION', 'DRIVER_VISION', 'PHYSICAL_CONDITION', 'PEDPEDAL_ACTION', 'PEDPEDAL_VISIBILITY', 'PEDPEDAL_LOCATION', 'BAC_RESULT VALUE', 'CELL_PHONE_USE']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "Vpa rd_no :  (234682, 1)\n",
      "Vpa unit 1 :  (234732, 31)\n",
      "Vpa unit 2 :  (234762, 61)\n",
      "Vpa unit 3 :  (234762, 91)\n",
      "Vpa unit 4 :  (234762, 121)\n",
      "Vpa unit 5 :  (234762, 151)\n",
      "Vpa unit 6 :  (234762, 181)\n",
      "cvp with duplicates: (234641, 203)\n",
      "cvp without duplicates: (234584, 203)\n",
      "Dataframe size after adding dummies to crashes columns:  (234584, 287)\n",
      "Dataframe size after adding dummies to vehicles columns:  (234584, 694)\n",
      "Dataframe size after adding dummies to peoples columns:  (234584, 929)\n",
      "last cell\n"
     ]
    }
   ],
   "source": [
    "import Preprocessing as pp\n",
    "\n",
    "#reload(pp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Splitting target variable from other variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pp.cvp_ohe\n",
    "train_data=df.copy(deep=True)\n",
    "train_data=train_data.drop(['PRIM_CONTRIBUTORY_CAUSE', 'SEC_CONTRIBUTORY_CAUSE'], axis=1)\n",
    "train_labels=df[['PRIM_CONTRIBUTORY_CAUSE']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "temp = df.copy(deep=True)\n",
    "temp1 = temp.iloc[:,0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Splitting to train and test / Scaling of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train_data, train_labels,test_size=0.20,stratify=train_labels,random_state=42)\n",
    "scaler=StandardScaler()\n",
    "X_train_scaled=scaler.fit_transform(X_train)\n",
    "X_test_scaled=scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithms Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### AdaBoostClassifier - Approach 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_selection=PCA(n_components=500)\n",
    "clf = AdaBoostClassifier(n_estimators=500)\n",
    "\n",
    "pipe_clf = make_pipeline(feature_selection,clf)\n",
    "pipe_clf.fit(X_train_scaled, y_train)\n",
    "y_pred_AB1 = pipe_clf.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********AdaBoost Classifier, Standard Scaled, PCA=500 ********\n",
      "F1-score_micro =  0.3713153014898651\n",
      "F1-score =  0.28723528509596524\n",
      "Precision =  0.2963381488209183\n",
      "Recall Score =  0.3713153014898651\n",
      "Stored 'f1_score_micro_AB1' (float64)\n",
      "Stored 'f1_score_wt_AB1' (float64)\n",
      "Stored 'precision_score_wt_AB1' (float64)\n",
      "Stored 'recall_score_wt_AB1' (float64)\n"
     ]
    }
   ],
   "source": [
    "print('********AdaBoost Classifier, Standard Scaled, PCA=500','********')\n",
    "f1_score_micro_AB1 = metrics.f1_score(y_test, y_pred_AB1, average='micro')\n",
    "f1_score_wt_AB1 = metrics.f1_score(y_test,y_pred_AB1,average='weighted')\n",
    "precision_score_wt_AB1=metrics.precision_score(y_test, y_pred_AB1, average='weighted')\n",
    "recall_score_wt_AB1=metrics.recall_score(y_test, y_pred_AB1, average='weighted')\n",
    "\n",
    "print('F1-score_micro = ',f1_score_micro_AB1)\n",
    "print('F1-score = ',f1_score_wt_AB1)\n",
    "print('Precision = ',precision_score_wt_AB1)\n",
    "print('Recall Score = ',recall_score_wt_AB1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### AdaBoostClassifier - Approach 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_selection=VarianceThreshold()\n",
    "clf = AdaBoostClassifier(n_estimators=500)\n",
    "pipe_clf = make_pipeline(feature_selection,clf)\n",
    "pipe_clf.fit(X_train_scaled, y_train)\n",
    "y_pred_AB2 = pipe_clf.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********AdaBoost Classifier, Standard Scaled, Variance threshold ********\n",
      "F1-score_micro =  0.5891254769060256\n",
      "F1-score =  0.5243464839292412\n",
      "Precision =  0.485709006203844\n",
      "Recall Score =  0.5891254769060256\n",
      "Stored 'f1_score_micro_AB2' (float64)\n",
      "Stored 'f1_score_wt_AB2' (float64)\n",
      "Stored 'precision_score_wt_AB2' (float64)\n",
      "Stored 'recall_score_wt_AB2' (float64)\n"
     ]
    }
   ],
   "source": [
    "print('********AdaBoost Classifier, Standard Scaled, Variance threshold','********')\n",
    "\n",
    "f1_score_micro_AB2 = metrics.f1_score(y_test, y_pred_AB2, average='micro')\n",
    "f1_score_wt_AB2 = metrics.f1_score(y_test,y_pred_AB2,average='weighted')\n",
    "precision_score_wt_AB2=metrics.precision_score(y_test, y_pred_AB2, average='weighted')\n",
    "recall_score_wt_AB2=metrics.recall_score(y_test, y_pred_AB2, average='weighted')\n",
    "\n",
    "print('F1-score_micro = ',f1_score_micro_AB2)\n",
    "print('F1-score = ',f1_score_wt_AB2)\n",
    "print('Precision = ',precision_score_wt_AB2)\n",
    "print('Recall Score = ',recall_score_wt_AB2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### AdaBoostClassifier - Approach 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_selection=TruncatedSVD(n_components=500)\n",
    "clf = AdaBoostClassifier(n_estimators=500)\n",
    "pipe_clf = make_pipeline(feature_selection,clf)\n",
    "pipe_clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred_AB3 = pipe_clf.predict(X_test_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********AdaBoost Classifier, Standard Scaled, Truncated SVD ********\n",
      "F1-score_micro =  0.39030628556813096\n",
      "F1-score =  0.287457340486424\n",
      "Precision =  0.3168707979116909\n",
      "Recall Score =  0.39030628556813096\n",
      "Stored 'f1_score_micro_AB3' (float64)\n",
      "Stored 'f1_score_wt_AB3' (float64)\n",
      "Stored 'precision_score_wt_AB3' (float64)\n",
      "Stored 'recall_score_wt_AB3' (float64)\n"
     ]
    }
   ],
   "source": [
    "print('********AdaBoost Classifier, Standard Scaled, Truncated SVD','********')\n",
    "\n",
    "f1_score_micro_AB3 = metrics.f1_score(y_test, y_pred_AB3, average='micro')\n",
    "f1_score_wt_AB3 = metrics.f1_score(y_test,y_pred_AB3,average='weighted')\n",
    "precision_score_wt_AB3 = metrics.precision_score(y_test, y_pred_AB3, average='weighted')\n",
    "recall_score_wt_AB3 = metrics.recall_score(y_test, y_pred_AB3, average='weighted')\n",
    "\n",
    "print('F1-score_micro = ',f1_score_micro_AB3)\n",
    "print('F1-score = ',f1_score_wt_AB3)\n",
    "print('Precision = ',precision_score_wt_AB3)\n",
    "print('Recall Score = ',recall_score_wt_AB3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### MultiLayerPerceptron - Approach 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_selection=PCA(n_components=500)\n",
    "clf = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5, 2), random_state=1)\n",
    "\n",
    "pipe_clf = make_pipeline(feature_selection,clf)\n",
    "pipe_clf.fit(X_train_scaled, y_train)\n",
    "y_pred_MLP1 = pipe_clf.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********MultiLayerPerceptron, Standard Scaled, PCA ********\n",
      "F1-score_micro =  0.574141569154038\n",
      "F1-score =  0.4866327189386002\n",
      "Precision =  0.42636022996432815\n",
      "Recall Score =  0.574141569154038\n",
      "Stored 'f1_score_micro_MLP1' (float64)\n",
      "Stored 'f1_score_wt_MLP1' (float64)\n",
      "Stored 'precision_score_wt_MLP1' (float64)\n",
      "Stored 'recall_score_wt_MLP1' (float64)\n"
     ]
    }
   ],
   "source": [
    "print('********MultiLayerPerceptron, Standard Scaled, PCA','********')\n",
    "\n",
    "f1_score_micro_MLP1 = metrics.f1_score(y_test, y_pred_MLP1, average='micro')\n",
    "f1_score_wt_MLP1 = metrics.f1_score(y_test,y_pred_MLP1,average='weighted')\n",
    "precision_score_wt_MLP1 = metrics.precision_score(y_test, y_pred_MLP1, average='weighted')\n",
    "recall_score_wt_MLP1 = metrics.recall_score(y_test, y_pred_MLP1, average='weighted')\n",
    "\n",
    "print('F1-score_micro = ',f1_score_micro_MLP1)\n",
    "print('F1-score = ',f1_score_wt_MLP1)\n",
    "print('Precision = ',precision_score_wt_MLP1)\n",
    "print('Recall Score = ',recall_score_wt_MLP1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### MultiLayerPerceptron - Approach 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_selection=VarianceThreshold()\n",
    "clf = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5, 2), random_state=1)\n",
    "\n",
    "pipe_clf = make_pipeline(feature_selection,clf)\n",
    "pipe_clf.fit(X_train_scaled, y_train)\n",
    "y_pred_MLP2 = pipe_clf.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********MultiLayerPerceptron, Standard Scaled, Variance threshold ********\n",
      "F1-score_micro =  0.5771042479271906\n",
      "F1-score =  0.48669357506748856\n",
      "Precision =  0.42307162561214745\n",
      "Recall Score =  0.5771042479271906\n",
      "Stored 'f1_score_micro_MLP2' (float64)\n",
      "Stored 'f1_score_wt_MLP2' (float64)\n",
      "Stored 'precision_score_wt_MLP2' (float64)\n",
      "Stored 'recall_score_wt_MLP2' (float64)\n"
     ]
    }
   ],
   "source": [
    "print('********MultiLayerPerceptron, Standard Scaled, Variance threshold','********')\n",
    "\n",
    "f1_score_micro_MLP2 = metrics.f1_score(y_test, y_pred_MLP2, average='micro')\n",
    "f1_score_wt_MLP2 = metrics.f1_score(y_test,y_pred_MLP2,average='weighted')\n",
    "precision_score_wt_MLP2 = metrics.precision_score(y_test, y_pred_MLP2, average='weighted')\n",
    "recall_score_wt_MLP2 = metrics.recall_score(y_test, y_pred_MLP2, average='weighted')\n",
    "\n",
    "print('F1-score_micro = ',f1_score_micro_MLP2)\n",
    "print('F1-score = ',f1_score_wt_MLP2)\n",
    "print('Precision = ',precision_score_wt_MLP2)\n",
    "print('Recall Score = ',recall_score_wt_MLP2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### MultiLayerPerceptron - Approach 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_selection=TruncatedSVD(n_components=500)\n",
    "clf = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5, 2), random_state=1)\n",
    "\n",
    "pipe_clf = make_pipeline(feature_selection,clf)\n",
    "pipe_clf.fit(X_train_scaled, y_train)\n",
    "y_pred_MLP3 = pipe_clf.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********MultiLayerPerceptron, Standard Scaled, Variance threshold ********\n",
      "F1-score_micro =  0.5691114095104121\n",
      "F1-score =  0.4797661628859421\n",
      "Precision =  0.42800934945299995\n",
      "Recall Score =  0.5691114095104121\n",
      "Stored 'f1_score_micro_MLP3' (float64)\n",
      "Stored 'f1_score_wt_MLP3' (float64)\n",
      "Stored 'precision_score_wt_MLP3' (float64)\n",
      "Stored 'recall_score_wt_MLP3' (float64)\n"
     ]
    }
   ],
   "source": [
    "print('********MultiLayerPerceptron, Standard Scaled, Variance threshold','********')\n",
    "\n",
    "f1_score_micro_MLP3 = metrics.f1_score(y_test, y_pred_MLP3, average='micro')\n",
    "f1_score_wt_MLP3 = metrics.f1_score(y_test,y_pred_MLP3,average='weighted')\n",
    "precision_score_wt_MLP3 = metrics.precision_score(y_test, y_pred_MLP3, average='weighted')\n",
    "recall_score_wt_MLP3 = metrics.recall_score(y_test, y_pred_MLP3, average='weighted')\n",
    "\n",
    "print('F1-score_micro = ',f1_score_micro_MLP3)\n",
    "print('F1-score = ',f1_score_wt_MLP3)\n",
    "print('Precision = ',precision_score_wt_MLP3)\n",
    "print('Recall Score = ',recall_score_wt_MLP3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### BaggingClassifierWithKNN - Approach 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_selection=PCA(n_components=500)\n",
    "clf = BaggingClassifier(KNeighborsClassifier(), max_samples=0.5, max_features=0.5)\n",
    "\n",
    "pipe_clf = make_pipeline(feature_selection,clf)\n",
    "pipe_clf.fit(X_train_scaled, y_train)\n",
    "y_pred_BGKNN1 = pipe_clf.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********Bagging Classifier with KNN, Standard Scaled, PCA ********\n",
      "F1-score_micro =  0.5130762836498497\n",
      "F1-score =  0.46687677262776517\n",
      "Precision =  0.47935536684781616\n",
      "Recall Score =  0.5130762836498497\n",
      "Stored 'f1_score_micro_BGKNN1' (float64)\n",
      "Stored 'f1_score_wt_BGKNN1' (float64)\n",
      "Stored 'precision_score_wt_BGKNN1' (float64)\n",
      "Stored 'recall_score_wt_BGKNN1' (float64)\n"
     ]
    }
   ],
   "source": [
    "print('********Bagging Classifier with KNN, Standard Scaled, PCA','********')\n",
    "\n",
    "f1_score_micro_BGKNN1 = metrics.f1_score(y_test, y_pred_BGKNN1, average='micro')\n",
    "f1_score_wt_BGKNN1 = metrics.f1_score(y_test,y_pred_BGKNN1,average='weighted')\n",
    "precision_score_wt_BGKNN1 = metrics.precision_score(y_test, y_pred_BGKNN1, average='weighted')\n",
    "recall_score_wt_BGKNN1 = metrics.recall_score(y_test, y_pred_BGKNN1, average='weighted')\n",
    "\n",
    "print('F1-score_micro = ',f1_score_micro_BGKNN1)\n",
    "print('F1-score = ',f1_score_wt_BGKNN1)\n",
    "print('Precision = ',precision_score_wt_BGKNN1)\n",
    "print('Recall Score = ',recall_score_wt_BGKNN1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### BaggingClassifierWith ExtraTrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_selection=VarianceThreshold()\n",
    "clf = BaggingClassifier(ExtraTreesClassifier()) \n",
    "\n",
    "pipe_clf = make_pipeline(feature_selection,clf)\n",
    "pipe_clf.fit(X_train_scaled, y_train)\n",
    "y_pred_BGET2 = pipe_clf.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********Bagging Classifier with Extra Tree, Standard Scaled, VarianceThreshold ********\n",
      "F1-score_micro =  0.63682673657736\n",
      "F1-score =  0.5887391749892716\n",
      "Precision =  0.6149740094068243\n",
      "Recall Score =  0.63682673657736\n",
      "Stored 'f1_score_micro_BGET2' (float64)\n",
      "Stored 'f1_score_wt_BGET2' (float64)\n",
      "Stored 'precision_score_wt_BGET2' (float64)\n",
      "Stored 'recall_score_wt_BGET2' (float64)\n"
     ]
    }
   ],
   "source": [
    "print('********Bagging Classifier with Extra Tree, Standard Scaled, VarianceThreshold','********')\n",
    "\n",
    "f1_score_micro_BGET2 = metrics.f1_score(y_test, y_pred_BGET2, average='micro')\n",
    "f1_score_wt_BGET2 = metrics.f1_score(y_test,y_pred_BGET2,average='weighted')\n",
    "precision_score_wt_BGET2 = metrics.precision_score(y_test, y_pred_BGET2, average='weighted')\n",
    "recall_score_wt_BGET2 = metrics.recall_score(y_test, y_pred_BGET2, average='weighted')\n",
    "\n",
    "print('F1-score_micro = ',f1_score_micro_BGET2)\n",
    "print('F1-score = ',f1_score_wt_BGET2)\n",
    "print('Precision = ',precision_score_wt_BGET2)\n",
    "print('Recall Score = ',recall_score_wt_BGET2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### BaggingClassifierWithRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_selection=VarianceThreshold()\n",
    "clf = BaggingClassifier(RandomForestClassifier()) \n",
    "\n",
    "pipe_clf = make_pipeline(feature_selection,clf)\n",
    "pipe_clf.fit(X_train_scaled, y_train)\n",
    "y_pred_BRF2 = pipe_clf.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********Bagging Classifier with RF, Standard Scaled, TruncatedSVD ********\n",
      "F1-score_micro =  0.6347805699426647\n",
      "F1-score =  0.582609915693631\n",
      "Precision =  0.6196219322048684\n",
      "Recall Score =  0.6347805699426647\n",
      "Stored 'f1_score_micro_BRF2' (float64)\n",
      "Stored 'f1_score_wt_BRF2' (float64)\n",
      "Stored 'precision_score_wt_BGRF2' (float64)\n",
      "Stored 'recall_score_wt_BGRF2' (float64)\n"
     ]
    }
   ],
   "source": [
    "print('********Bagging Classifier with RF, Standard Scaled, Variance Threshold','********')\n",
    "\n",
    "f1_score_micro_BRF2 = metrics.f1_score(y_test, y_pred_BRF2, average='micro')\n",
    "f1_score_wt_BRF2 = metrics.f1_score(y_test,y_pred_BRF2,average='weighted')\n",
    "precision_score_wt_BGRF2 = metrics.precision_score(y_test, y_pred_BRF2, average='weighted')\n",
    "recall_score_wt_BGRF2 = metrics.recall_score(y_test, y_pred_BRF2, average='weighted')\n",
    "\n",
    "print('F1-score_micro = ',f1_score_micro_BRF2)\n",
    "print('F1-score = ',f1_score_wt_BRF2)\n",
    "print('Precision = ',precision_score_wt_BGRF2)\n",
    "print('Recall Score = ',recall_score_wt_BGRF2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Bagging with LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_selection=VarianceThreshold()\n",
    "clf = BaggingClassifier(LinearDiscriminantAnalysis()) \n",
    "\n",
    "pipe_clf = make_pipeline(feature_selection,clf)\n",
    "pipe_clf.fit(X_train_scaled, y_train)\n",
    "y_pred_BLDA2 = pipe_clf.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********Bagging Classifier with LDA, Standard Scaled, Variance Threshold ********\n",
      "F1-score_micro =  0.5966494021356864\n",
      "F1-score =  0.5737261052110655\n",
      "Precision =  0.6060210255209738\n",
      "Recall Score =  0.5966494021356864\n",
      "Stored 'f1_score_micro_BLDA2' (float64)\n",
      "Stored 'f1_score_wt_BLDA2' (float64)\n",
      "Stored 'precision_score_wt_BLDA2' (float64)\n",
      "Stored 'recall_score_wt_BLDA2' (float64)\n"
     ]
    }
   ],
   "source": [
    "print('********Bagging Classifier with LDA, Standard Scaled, Variance Threshold','********')\n",
    "\n",
    "f1_score_micro_BLDA2 = metrics.f1_score(y_test, y_pred_BLDA2, average='micro')\n",
    "f1_score_wt_BLDA2 = metrics.f1_score(y_test,y_pred_BLDA2,average='weighted')\n",
    "precision_score_wt_BLDA2 = metrics.precision_score(y_test, y_pred_BLDA2, average='weighted')\n",
    "recall_score_wt_BLDA2 = metrics.recall_score(y_test, y_pred_BLDA2, average='weighted')\n",
    "\n",
    "print('F1-score_micro = ',f1_score_micro_BLDA2)\n",
    "print('F1-score = ',f1_score_wt_BLDA2)\n",
    "print('Precision = ',precision_score_wt_BLDA2)\n",
    "print('Recall Score = ',recall_score_wt_BLDA2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Bagging with Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_selection=VarianceThreshold()\n",
    "clf = BaggingClassifier(DecisionTreeClassifier()) \n",
    "\n",
    "pipe_clf = make_pipeline(feature_selection,clf)\n",
    "pipe_clf.fit(X_train_scaled, y_train)\n",
    "y_pred_BDT2 = pipe_clf.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********Bagging Classifier with DT, Standard Scaled, Variance Threshold ********\n",
      "F1-score_micro =  0.6267877315258862\n",
      "F1-score =  0.6008168379137391\n",
      "Precision =  0.5926255864563322\n",
      "Recall Score =  0.6267877315258862\n",
      "Stored 'f1_score_micro_BDT2' (float64)\n",
      "Stored 'f1_score_wt_BDT2' (float64)\n",
      "Stored 'precision_score_wt_BDT2' (float64)\n",
      "Stored 'recall_score_wt_BDT2' (float64)\n"
     ]
    }
   ],
   "source": [
    "print('********Bagging Classifier with DT, Standard Scaled, Variance Threshold','********')\n",
    "\n",
    "f1_score_micro_BDT2 = metrics.f1_score(y_test, y_pred_BDT2, average='micro')\n",
    "f1_score_wt_BDT2 = metrics.f1_score(y_test,y_pred_BDT2,average='weighted')\n",
    "precision_score_wt_BDT2 = metrics.precision_score(y_test, y_pred_BDT2, average='weighted')\n",
    "recall_score_wt_BDT2 = metrics.recall_score(y_test, y_pred_BDT2, average='weighted')\n",
    "\n",
    "print('F1-score_micro = ',f1_score_micro_BDT2)\n",
    "print('F1-score = ',f1_score_wt_BDT2)\n",
    "print('Precision = ',precision_score_wt_BDT2)\n",
    "print('Recall Score = ',recall_score_wt_BDT2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "algorithm_3 = {'f1_score_micro_AB1':f1_score_micro_AB1,\n",
    "'f1_score_wt_AB1': f1_score_wt_AB1,\n",
    "'precision_score_wt_AB1': precision_score_wt_AB1,\n",
    "'recall_score_wt_AB1':recall_score_wt_AB1,\n",
    "'f1_score_micro_AB2':f1_score_micro_AB2,\n",
    "'f1_score_wt_AB2':f1_score_wt_AB2,\n",
    "'precision_score_wt_AB2':precision_score_wt_AB2,\n",
    "'recall_score_wt_AB2':recall_score_wt_AB2,\n",
    "'f1_score_micro_AB3':f1_score_micro_AB3,\n",
    "'f1_score_wt_AB3':f1_score_wt_AB3,\n",
    "'precision_score_wt_AB3':precision_score_wt_AB3,\n",
    "'recall_score_wt_AB3':recall_score_wt_AB3,\n",
    "'f1_score_micro_MLP1':f1_score_micro_MLP1,\n",
    "'f1_score_wt_MLP1':f1_score_wt_MLP1,\n",
    "'precision_score_wt_MLP1':precision_score_wt_MLP1,\n",
    "'recall_score_wt_MLP1':recall_score_wt_MLP1,\n",
    "'f1_score_micro_MLP2':f1_score_micro_MLP2,\n",
    "'f1_score_wt_MLP2':f1_score_wt_MLP2,\n",
    "'precision_score_wt_MLP2':precision_score_wt_MLP2,\n",
    "'recall_score_wt_MLP2':recall_score_wt_MLP2,\n",
    "'f1_score_micro_MLP3':f1_score_micro_MLP3,\n",
    "'f1_score_wt_MLP3':f1_score_wt_MLP3,\n",
    "'precision_score_wt_MLP3':precision_score_wt_MLP3,\n",
    "'recall_score_wt_MLP3':recall_score_wt_MLP3,\n",
    "'f1_score_micro_BGKNN1':f1_score_micro_BGKNN1,\n",
    "'f1_score_wt_BGKNN1':f1_score_wt_BGKNN1,\n",
    "'precision_score_wt_BGKNN1':precision_score_wt_BGKNN1,\n",
    "'recall_score_wt_BGKNN1':recall_score_wt_BGKNN1,\n",
    "'f1_score_micro_BGET2':f1_score_micro_BGET2,\n",
    "'f1_score_wt_BGET2':f1_score_wt_BGET2,\n",
    "'precision_score_wt_BGET2':precision_score_wt_BGET2,\n",
    "'recall_score_wt_BGET2':recall_score_wt_BGET2,\n",
    "'f1_score_micro_BRF2':f1_score_micro_BRF2,\n",
    "'f1_score_wt_BRF2':f1_score_wt_BRF2,\n",
    "'precision_score_wt_BGRF2':precision_score_wt_BGRF2,\n",
    "'recall_score_wt_BGRF2':recall_score_wt_BGRF2,\n",
    "'f1_score_micro_BLDA2':f1_score_micro_BLDA2,\n",
    "'f1_score_wt_BLDA2':f1_score_wt_BLDA2,\n",
    "'precision_score_wt_BLDA2':precision_score_wt_BLDA2,\n",
    "'recall_score_wt_BLDA2':recall_score_wt_BLDA2,\n",
    "'f1_score_micro_BDT2':f1_score_micro_BDT2,\n",
    "'f1_score_wt_BDT2':f1_score_wt_BDT2,\n",
    "'precision_score_wt_BDT2':precision_score_wt_BDT2,\n",
    "'recall_score_wt_BDT2':recall_score_wt_BDT2\n",
    "}\n",
    "\n",
    "pickle.dump(algorithm_3,open(\"algorithm_3.p\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
